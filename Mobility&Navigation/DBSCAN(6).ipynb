{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWw2VZlnhK0w"
   },
   "source": [
    "**Density-Based Spatial Clustering Applications with Noise**\n",
    "\n",
    "While k-means clustering relied on providing the number of clusters beforehand, the DBSCAN algorithm is a non-parametric algorithm. Given a set of points, DBSCAN groups together points that are close to each other while also marking outliers. This algorithm can identify clusters even in large spatial datasets by simply highlighting the local density of points. It is also one of the most widely used clustering algorithms, especially for location data. DBSCAN requires two parameters to be supplied before running the algorithm: epsilon and minimum points or samples. Their values significantly influence the results of this algorithm and therefore require some fine-tuning, as well as exploration, before finding suitable clusters.\n",
    "\n",
    "Epsilon is the parameter that specifies the radius of a neighborhood with respect to other points. In a given set of points, epsilon indicates the distance a point lies closer to a cluster of other points. On the other hand, minimum samples or points set the minimum number of points needed to form a cluster. Based on these two parameters, DBSCAN classifies into three types (this can be more or less depending on these two parameters, but at least one cluster is present):\n",
    "\n",
    "- Core points (0): A point is a core point when it fulfils the epsilon distance, has the minimum points, and is a neighbor with another core point.\n",
    "- Border points (1 to n): A point is a border point when it does not fulfil the minimum points required but does share a neighborhood with at least one core point. The number of clusters in this category can be many depending on the parameters. \n",
    "- Noise Points (-1): A point that does not fulfil the epsilon distance, does not have the minimum points required, and does not share any neighborhood with other core points is known as noise. These are considered outliers.\n",
    "\n",
    "We can use DBSCAN to primarily detect outliers or noise or in contrast main clusters. We will cover both of these use cases in the next two sections: Detecting outliers and Detecting clusters. We will be using the DBSCAN algorithm from the scikit-learn library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "201iMWDJhwWd"
   },
   "source": [
    "***Detecting outliers***\n",
    "\n",
    "Let's first create coordinates out of the latitude and longitude for the whole data, since we do not need to split the train and test dataset for this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD36KU0bhFCu"
   },
   "outputs": [],
   "source": [
    "coords = crime_somerset_gdf[['Latitude', 'Longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hdjhJMwh7Yv"
   },
   "source": [
    "Now, we are all set to apply DBSCAN on the coordinates. DBSCAN returns tuples; we are only interested in the labels and not the index and therefore we label it a _ symbol, which denotes generally unwanted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7vi2bbBh8cZ"
   },
   "outputs": [],
   "source": [
    "_, labels = dbscan(crime_somerset_gdf[['Latitude', 'Longitude']], eps=0.1, min_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jKaq9P3iFAz"
   },
   "source": [
    "Here, we pass an epsilon of 0.1 and minimum samples of 10 points, a higher epsilon and lower samples to detect outliers. Let's create a DataFrame out of the labels result and group according to the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yybYTgGuiGI6"
   },
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(labels, index=crime_somerset_gdf.index, columns=['cluster'])\n",
    "labels_df.groupby('cluster').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqXGeA_0iOfC"
   },
   "source": [
    "With these epsilon and minimum sample parameters, DBSCAN results indicate that only 18 points are classified as noise or outliers, while all other points fall into the core cluster. Let's assign each category a name and plot it to see the results.\n",
    "\n",
    "First, we subset the noise and core from labels_df and create a separate DataFrame for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kmxk13qWiPsm"
   },
   "outputs": [],
   "source": [
    "noise = crime_somerset_gdf.loc[labels_df['cluster']==-1, ['Latitude', 'Longitude']]\n",
    "core = crime_somerset_gdf.loc[labels_df['cluster']== 0, ['Latitude', 'Longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlJWQAvJiWR6"
   },
   "source": [
    "Now, we will plot them using the scatter plot. Here, we use it to display the noise as stars while the core is displayed as circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46e_a8_7iY7L"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax.scatter(noise['Latitude'], noise['Longitude'],marker= '*', s=40, c='blue' )\n",
    "ax.scatter(core['Latitude'], core['Longitude'], marker= 'o', s=20, c='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0i2SEV4iifjq"
   },
   "source": [
    "The scatter plot for the results is as follows. As you can see, the 18 points detected as noise (outliers) are displayed as stars while the core points are displayed as circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1mUbJ3IilwN"
   },
   "source": [
    "DBSCAN algorithm clusters: outlier detection\n",
    "\n",
    "We can also use DBSCAN to detect clusters instead of outliers. In the following section, we will cover tweaking this algorithm to detect clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncCjWgCJin1Q"
   },
   "source": [
    "***Detecting clusters***\n",
    "\n",
    "To detect clusters, we need to make the epsilon lower while increasing the minimum samples. Let's look at one example of such a scenario. We will set the epsilon as 0.01 and make the minimum samples higher, at 300 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP7Gaoueij0a"
   },
   "outputs": [],
   "source": [
    "_, labels = dbscan(crime_somerset_gdf[['Latitude', 'Longitude']], eps=0.01, min_samples=300)\n",
    "labels_df = pd.DataFrame(labels, index=crime_somerset_gdf.index, columns=['cluster'])\n",
    "labels_df.groupby('cluster').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gntusIxai_J3"
   },
   "source": [
    "In this case, we have more than two clusters as there are some border points (three border point clusters). Let's create a cluster for each one of them and plot them in a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4kFv9OgjBPv"
   },
   "outputs": [],
   "source": [
    "noise = crime_somerset_gdf.loc[labels_df['cluster']==-1, ['Latitude', 'Longitude']]\n",
    "core = crime_somerset_gdf.loc[labels_df['cluster']== 0, ['Latitude', 'Longitude']]\n",
    "bp1 = crime_somerset_gdf.loc[labels_df['cluster']== 1, ['Latitude', 'Longitude']]\n",
    "bp2 = crime_somerset_gdf.loc[labels_df['cluster']== 2, ['Latitude', 'Longitude']]\n",
    "bp3 = crime_somerset_gdf.loc[labels_df['cluster']== 3, ['Latitude', 'Longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMROdUMDjFgg"
   },
   "source": [
    "Now that we have created each cluster into a separate DataFrame, we can plot them using a scatter plot, as follows. To display the image clearly, we also limit the x axis and y axis to zoom into the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSQUL6j5jKMr"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "ax.scatter(noise['Latitude'], noise['Longitude'],s=1, c='gray' )\n",
    "ax.scatter(core['Latitude'], core['Longitude'],marker= \"*\", s=10, c='red')\n",
    "ax.scatter(bp1['Latitude'], bp1['Longitude'], marker = \"v\", s=10, c='yellow')\n",
    "ax.scatter(bp2['Latitude'], bp2['Longitude'], marker= \"P\", s=10, c='green')\n",
    "ax.scatter(bp3['Latitude'], bp3['Longitude'], marker= \"d\", s=10, c='blue')\n",
    "ax.set_xlim(left=50.8, right=51.7)\n",
    "ax.set_ylim(bottom=-3.5, top=-2.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLoaWn_9kgcp"
   },
   "source": [
    "The output of the scatter plot is shown in the following diagram. There are five clusters detected. The noise (-1) is shown as circles and these are dimmed. The core points are shown with star markers and lie on clustered points at the upper north area of the plot. The three lower clusters are border points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btkHf5-skpXG"
   },
   "source": [
    "Zoomed cluster detection with DBSCAN \n",
    "\n",
    "This clearly shows where clusters lie in our data. In the next section, we will cover more elaborate cluster detection techniques using spatial autocorrelation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIYJcqRDAa4w1/bHu+K5gv",
   "collapsed_sections": [],
   "name": "DBSCAN(6).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
