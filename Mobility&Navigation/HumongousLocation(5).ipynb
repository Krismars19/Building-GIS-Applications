{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HumongousLocation(5).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtsBxuv1uF6X0dmwGjpsUf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8XJ0C34hYsFB"},"source":["**Making Sense of Humongous Location Datasets**\n","\n","Geospatial clustering techniques handle these problems by reducing the dimensionality of location data into smaller, manageable, and relevant variables for the data analysis process. Clustering technique importance increases as the amount of data grows. \n","\n","We will use machine learning and spatial statistics to derive an insightful location analysis with less dimensional complexity. We will cover the following topics in this chapter:\n","\n","- K-means clustering\n","- Density-Based Spatial Clustering Applications with Noise (DBSCAN)\n","- Spatial autocorrelation"]},{"cell_type":"markdown","metadata":{"id":"AAFK0dtMbcip"},"source":["***K-means clustering***\n","\n","K-means clustering is one of the most widely used unsupervised machine learning techniques and is used mainly for data mining purposes. In a classic k-means clustering, the full weights are on attribute similarity, while location-based k-means specifically targets geographic coordinates to derive spatial or location similarity. We will use the latter as we are interested in location data analysis. \n","\n","The k-means algorithm is based on randomly selecting k (where k is the number of clusters specified) number of objects that represent initially a cluster mean or center. Then, the algorithm assigns other objects to the cluster, which is closely based on the Euclidean distance between the object and cluster mean. The k-means process is iterative and requires heavy computations when applied to a large dataset as it goes through each object iteratively. "]},{"cell_type":"markdown","metadata":{"id":"1Z2P_S4_cS6S"},"source":["*The crime dataset*"]},{"cell_type":"code","metadata":{"id":"zxjHuse0YHOs"},"source":["# Read the dataset\n","\n","crime_somerset = pd.read_csv(\"2019-02-avon-and-somerset-street.csv\")\n","crime_somerset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YlKTW0bGcqQU"},"source":["*Cleaning data*\n","\n","It is necessary to carry out preprocessing and cleaning out data. \n","\n","Let's check first how many null values we have in our data. We use the pandas .isnull() function and .sum() to get each column's total null values"]},{"cell_type":"code","metadata":{"id":"HhDuz8q3dLRd"},"source":["crime_somerset.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3tnFj_Bge7HE"},"source":["We can drop all columns with more than a threshold, for example, 2,000 rows of missing values while maintaining columns with missing values less than the specified number (2,000 in our case)"]},{"cell_type":"code","metadata":{"id":"87G0UWbGe-aF"},"source":["crime_somerset.drop(['Last outcome category','Context', 'Crime ID' ], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dlc0_xNSfEuL"},"source":["We need to drop rows of missing values to clean our data and get it ready for machine learning models. To drop rows with any missing values in the dataset, we can do the following"]},{"cell_type":"code","metadata":{"id":"Qi30C1KZfGOl"},"source":["crime_somerset.dropna(axis=0,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wa8rC1EXfNDK"},"source":["If you run this code again, you will see that the whole dataset does not have any missing values"]},{"cell_type":"code","metadata":{"id":"lyQKieo4fOEE"},"source":["crime_somerset.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-r9FvVnfYXK"},"source":["Let's convert the pandas DataFrame into a GeoPandas GeoDataFrame\n","\n","Here is a function that creates a GeoDataFrame using a pandas DataFrame. We can use this function to create a GeoDataFrame from any CSV file with Latitude and Longitude columns"]},{"cell_type":"code","metadata":{"id":"kJQpEI2Kflxd"},"source":["def create_gdf(df, lat, lon):\n","  \"\"\" Convert pandas dataframe into a Geopandas GeoDataFrame\"\"\"\n","  crs = {'init': 'epsg:4326'}\n","  geometry = [Point(xy) for xy in zip(airbnb[lon], airbnb[lat])]\n","  gdf = gpd.GeoDataFrame(airbnb, crs=crs, geometry=geometry)\n","  return gdf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8O9DfIZ_f37S"},"source":["Now that we have created a function to convert a pandas DataFrame into a GeoPandas GeoDataFrame, we can use to call that function by providing the names of the coordinates in case the dataset has different names for latitude and longitude. Let's call the function on the crime dataset"]},{"cell_type":"code","metadata":{"id":"haFiOLC1f49x"},"source":["crime_somerset_gdf = create_gdf(crime_somerset, 'Latitude', 'Longitude')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bzz2IgROgDwo"},"source":["**K-means clustering with scikit-learn**\n","\n","To apply k-means clustering on location data, we need to get the coordinates of these features. Before we do that, we will split the dataset into train and test datasets. The test dataset will be used for predicting which group a point belongs to"]},{"cell_type":"code","metadata":{"id":"66OjF9pPgLTd"},"source":["from sklearn.cluster import KMeans\n","\n","train = airbnb.sample(frac=0.7, random_state=14)\n","test = airbnb.drop(train.index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U4npkd0mgV-Y"},"source":["Now that we have created a training and test dataset, let's store training and test coordinates"]},{"cell_type":"code","metadata":{"id":"neUoWqFTgVl1"},"source":["train_coords = train[['latitude', 'longitude']].values\n","test_coords = test[['latitude', 'longitude']].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sRxtTsxpgeb0"},"source":["Let's compute k-means clustering. In this example, we arbitrarily choose 5 clusters"]},{"cell_type":"code","metadata":{"id":"N78sGGtggfVB"},"source":["kmeans = KMeans(n_clusters=5)\n","kmeans.fit(train_coords)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nH2eVUGnglb7"},"source":["Then, we compute cluster centers and predict the cluster index for each sample"]},{"cell_type":"code","metadata":{"id":"mG_GMGRCgozV"},"source":["preds = kmeans.predict(test_coords)\n","centers = kmeans.cluster_centers_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRgcnzDpgsNj"},"source":["Let's visualize the 5 cluster outputs of the predictions from the test dataset"]},{"cell_type":"code","metadata":{"id":"fZgKRtefgvOI"},"source":["fig, ax = plt.subplots(figsize=(12,10))\n","plt.scatter(test_coords[:, 0], test_coords[:, 1], c=preds, s=30, cmap='viridis')\n","plt.scatter(centers[:,0], centers[:,1], c='Red', marker=\"s\", s=50);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0TaPiRb5g4_8"},"source":["K-means clustering with five clusters\n","\n","The center points are displayed as squares while other cluster points are displayed as a circle point. Each cluster measures how close it is to that mean. We have some outlier points here at the corners, but they clearly show how the k-means algorithm works in this case. Each point is clustered according to the nearest center mean point"]},{"cell_type":"code","metadata":{"id":"tGAhmXLog4G0"},"source":[""],"execution_count":null,"outputs":[]}]}