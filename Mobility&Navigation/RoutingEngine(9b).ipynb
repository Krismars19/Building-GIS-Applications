{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYQTNxBbGZgw"
   },
   "source": [
    "**Building a graph based on a road network**\n",
    "\n",
    "In the previous sections, we learned about the fundamentals of the graph and many of the operations that we can perform on a graph using sample data that we defined. In this section, we will discuss how to import real-world data such as a road network and translate it into a graph and perform analyses on that. For this purpose, we will be importing sample Open Street Maps (OSM) road data that we have provided with this chapter. \n",
    "\n",
    "***Open Street Maps data***\n",
    "\n",
    "OSM provides a rich set of open source and crowdsourced geographic data of many parts of the world. In particular, we are interested in the road data they provide. For the US, they are baselined on census TIGER road shapefiles and benefit from continuous updates by the active OSM community. OSM road data provide critical information such as the following:\n",
    "\n",
    "- Road geometry\n",
    "- Road direction\n",
    "- Road speed limit\n",
    "- Traffic signs and impediments (pedestrian crossings and so on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6rcSdBvGqak"
   },
   "source": [
    "Exploring the road data \n",
    "For reading the shapefiles, we will be using the GeoPandas library and Shapely geometry modules. If GeoPandas is not installed, install it using pip or any similar package manager. The pip installation code is shown as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RzGql0JGPg2"
   },
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3qdeClLGySE"
   },
   "source": [
    "To execute the code further, please download the BayArea4 shapefiles from our data repository into the folder where your Jupyter Notebook resides. \n",
    "\n",
    "Let's now import the rest of the libraries required to create our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKW7ACqHG1ga"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxQC0su0G6GC"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "roads_df = gpd.read_file('Roads_BayArea4.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BL8X63HBHBkq"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "roads_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X5Yl0HgHQ88"
   },
   "source": [
    "***DataFrame view of roads GeoDataFrame***\n",
    "\n",
    "The maxspeed column is of particular interest since it defines the maximum speed in which someone can traverse that road segment as permitted by law. If we need to create a time-based routing, we need to leverage this field. But before doing that, we need to make sure that the field provides us with complete information. To do that, let's execute the following code, which provides us with the sum of rows with null values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3bOE_igHUWd"
   },
   "outputs": [],
   "source": [
    "roads_df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2zT353kHXSR"
   },
   "source": [
    "A first look at the preceding response looks promising. None of the rows in the maxspeed column have null values. However, it might be possible that most of the null values for the maxspeed column are substituted by 0, which is an unacceptable value if we were to use the maxspeed column to derive the time taken to traverse a road segment. Let's confirm that this isn't the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e6xeYtGHY3k"
   },
   "outputs": [],
   "source": [
    "len(roads_df[roads_df[\"maxspeed\"] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdwrUN51Hgc6"
   },
   "source": [
    "35,000 out of 54,000 records have 0 as a value for maxspeed. So, we need to find a proxy to calculate the values for maxspeed. This will be discussed in detail in the following sections. For now, let's try to visualize the roads GeoDataframe as a simple plot using the following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG5S0Md0Hhgh"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "roads_df.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tQnZLOXHnrq"
   },
   "source": [
    "The simple plot of the roads' GeoDataFrame shown here reveals to us the line geometry of the roads and the network it forms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaZ-RyRbHp_y"
   },
   "source": [
    "**Creating a graph from a DataFrame **\n",
    "\n",
    "The following steps are required to create a graph from our DataFrame:\n",
    "\n",
    "- Reading and exploding the geometry\n",
    "- Calculating the distance of each edge in meters\n",
    "- Finding a proxy for zero values of maxspeed\n",
    "- Accounting for directionality\n",
    "- Calculating drive time in seconds for each edge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URI7Q5a7HzZk"
   },
   "source": [
    "***Reading and exploding the geometry***\n",
    "\n",
    "The geometry column holds the key to constructing the edges required for our road network graph. Let's read just a random row for and play around with the geometry column and try to make sense of it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8J2E8EI2H3sd"
   },
   "outputs": [],
   "source": [
    "frow = roads_df.iloc[1000]\n",
    "print(\"{frow}\\n\\n\")\n",
    "print(\"Coords : {frow['geometry'].xy}\\n\\n\")\n",
    "print(\"Length {frow['geometry'].length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnlcZc3cH-jC"
   },
   "source": [
    "We picked up the 1,001st row and tried to print out the information in the row and the geometric information such as the coordinates in the geometry LineString and the length of the LineString. The length of the LineString is in decimal degrees and doesn't make much sense and is not useful to us, but the coordinates of the LineString are. The coordinates are available as a tuple of NumPy arrays, with the first item in the tuple being the NumPy array of longitudes and the second item being the array of latitudes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDtSk0L1IEmi"
   },
   "source": [
    "How do these coordinates look in the real world? Well, wonder no more; a simple matplot plotting will answer that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-AHkxbRIHjz"
   },
   "outputs": [],
   "source": [
    "x, y = frow['geometry'].xy\n",
    "fig = plt.figure(1, figsize=(5,5), dpi=90)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FhoYN6sIOyU"
   },
   "source": [
    "Twenty-six coordinates were to create this sinuous road segment. This means that 25 graph edges be created from the 26 coordinates\n",
    "\n",
    "The following lines of codes accomplish these requirements.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BJsod3tIZYl"
   },
   "outputs": [],
   "source": [
    "def split_data_frame_list(df, target_column, col_name, output_type=list):\n",
    "    ''' \n",
    "    Accepts a column with multiple types and splits list variables to several rows.\n",
    "    df: dataframe to split\n",
    "    target_column: the column containing the values to split\n",
    "    col_name : name of the split column\n",
    "    output_type: type of column to be split\n",
    "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
    "    The values in the other columns are duplicated across the newly divided rows.\n",
    "    '''\n",
    "\n",
    "    row_accumulator = []\n",
    "\n",
    "    def split_list_to_rows(row):\n",
    "        split_row = row[target_column]\n",
    "        if isinstance(split_row, list):\n",
    "            for s in split_row:\n",
    "                new_row = row.to_dict()\n",
    "                new_row[col_name] = output_type(s)\n",
    "                row_accumulator.append(new_row)\n",
    "        else:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[col_name] = output_type(split_row)\n",
    "            row_accumulator.append(new_row)\n",
    "\n",
    "    df.apply(split_list_to_rows, axis=1)\n",
    "    new_df = pd.DataFrame.from_records(row_accumulator, columns=[df.columns])\n",
    " return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7u9UjPFIuOd"
   },
   "source": [
    "The preceding function explodes the road segments into individual rows, so that we have one edge per row. After defining the preceding function, we can execute the code provided as follows. This will create a new DataFrame: edge_df. edge_df will contain a geometry column that contains the edge coordinates. Two separate columns, source and target, should also be created. The source column will contain the first coordinate of the edge, and the target column will contain the second coordinate of the edge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nae8z9ztI4Qn"
   },
   "outputs": [],
   "source": [
    "roads_df[\"geometry_arr\"] = roads_df[\"geometry\"].apply(lambda geom : list(zip(*geom.xy)))\n",
    "roads_df[\"edge_list\"] =  roads_df[\"geometry_arr\"].apply(lambda coords : [[coords[i], coords[i+1]] for i in range(len(coords) - 1)])\n",
    "\n",
    "edge_df = split_data_frame_list(roads_df, \"edge_list\", \"geometry\")\n",
    "edge_df[\"source\"] = edge_df[\"geometry\"].apply(lambda edge: edge[0])\n",
    "edge_df[\"target\"] = edge_df[\"geometry\"].apply(lambda edge: edge[1])\n",
    "edge_df = edge_df.drop('geometry', axis = 1)\n",
    "edge_df = edge_df.drop('geometry_arr', axis = 1)\n",
    "roads_df = roads_df.drop([\"geometry_arr\", \"edge_list\"], axis = 1)\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oly989OfJju_"
   },
   "source": [
    "Calculating the distance of edges\n",
    "We can use the haversine function discussed in earlier chapters to calculate the distance for each edge. The following lines of code will add a dist column to edge_df and populate it with the length of the edge in meters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIE34XY0JoHk"
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt, atan2\n",
    "\n",
    "def haversine(loc1, loc2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    lon1, lat1 = loc1\n",
    "    lon2, lat2 = loc2\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6378100 # Radius of earth in meters. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "\n",
    "edge_df[\"dist\"] = edge_df.apply(lambda row: haversine(row[\"source\"], row[\"target\"]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoES0pJ4IrH4"
   },
   "source": [
    "***Finding a proxy for maximum speed ***\n",
    "\n",
    "Our job, at this point, is to find a proxy for maximum speed values when the value is not present (or populated by zero). The fclass column provides the best opportunity to impute this data. The data we are working with corresponds to the state of California. The following speed lookup for the fclass type holds good enough for California:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7oRFbbRJz9U"
   },
   "outputs": [],
   "source": [
    "speed_limits_in_mph = {\n",
    "  \"living_street\"     : 10,\n",
    "  \"motorway\"          : 65, \n",
    "  \"motorway_link\"     : 40, \n",
    "  \"primary\"           : 55,\n",
    "  \"primary_link\"      : 30,\n",
    "  \"residential\"       : 25, \n",
    "  \"secondary\"         : 35,\n",
    "  \"secondary_link\"    : 25,\n",
    "  \"service\"           : 15, \n",
    "  \"tertiary\"          : 35,\n",
    "  \"tertiary_link\"     : 25,\n",
    "  \"trunk\"             : 55, \n",
    "  \"trunk_link\"        : 30,\n",
    "  \"unclassified\"      : 55, \n",
    "  \"unknown\"           : 40\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol2mN6JtJ5-k"
   },
   "source": [
    "Update the maxspeed column in edge_df with the preceding lookup dictionary. Remember, the maxspeed column is in kilometers per hour and the lookup table speeds are provided in miles per hour. So, while updating maxspeed, a multiplicative factor of 1.609 is added to the lookup table speeds (since 1 mile = 1.609 km):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vuiVUZnJ8Ef"
   },
   "outputs": [],
   "source": [
    "edge_df[\"maxspeed\"] = edge_df.apply(lambda row: speed_limits_in_mph[row[\"fclass\"]] * 1.609 if row[\"maxspeed\"] == 0 else row[\"maxspeed\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBmnOXPdJ-7-"
   },
   "source": [
    "***Accounting for directionality***\n",
    "\n",
    "The directionality of the edges is defined in the oneway column. The definition for the column is provided in the data dictionary provided by the Geofabrik download site. \n",
    "\n",
    "For edges with oneway == 'F', no changes are required. For edges with oneway == 'T', the current edges have to flip, that is, the source and target values must be swapped. For edges with oneway == 'B', additional edges replicating the edge need to be added and then swapped. The following lines of code will achieve the preceding objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZxtxnZiKKWU"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "nt = edge_df.query(\"oneway != 'T'\", inplace = False)\n",
    "b = edge_df.query(\"oneway == 'B'\", inplace = False)\n",
    "\n",
    "src_tmp = b[\"source\"]\n",
    "b[\"source\"] = b[\"target\"]\n",
    "b[\"target\"] = src_tmp\n",
    "\n",
    "t = edge_df.query(\"oneway == 'T'\" , inplace = False)\n",
    "src_tmp = t[\"source\"]\n",
    "t[\"source\"] = t[\"target\"]\n",
    "t[\"target\"] = src_tmppd.options.mode.chained_assignment = None\n",
    "nt = edge_df.query(\"oneway != 'T'\", inplace = False)\n",
    "b = edge_df.query(\"oneway == 'B'\", inplace = False)\n",
    "\n",
    "src_tmp = b[\"source\"]\n",
    "b[\"source\"] = b[\"target\"]\n",
    "b[\"target\"] = src_tmp\n",
    "\n",
    "t = edge_df.query(\"oneway == 'T'\" , inplace = False)\n",
    "src_tmp = t[\"source\"]\n",
    "t[\"source\"] = t[\"target\"]\n",
    "t[\"target\"] = src_tmp\n",
    "\n",
    "edge_df = pd.concat([nt, b, t], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06gjkQggKOju"
   },
   "source": [
    "***Calculating drivetime***\n",
    "\n",
    "Drivetime for the edges can be calculated using the middle school Time and Distance calculations. The following formulae and conversion will help our time calculations: \n",
    "\n",
    "Time = Distance / SpeedTime (in seconds) = (Distance (in meters) / Speed (in kmph) ) * (18/5)\n",
    "\n",
    "Let's implement this formula with the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDte1mbIKRh8"
   },
   "outputs": [],
   "source": [
    "edge_df[\"time\"] = (edge_df[\"dist\"]/edge_df[\"maxspeed\"]) * (18/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS18m1GMKUPR"
   },
   "source": [
    "We have hence effectively added a time column. No more processing is needed for the DataFrame at this point. We are ready to convert this into a graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV9dlSqYKXLh"
   },
   "source": [
    "***Building the graph***\n",
    "\n",
    "We have already discussed how to convert a pandas DataFrame into a graph using the networkx method known as from_pandas_edgelist(). Since our edge_df already contains the source and target columns, we need not mention it explicitly in the method. To keep the footprint of the graph light, let's only include the most essential data from the DataFrame as edge attributes. Here, we are adding osm_id, name, and time as edge attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwY2z-M5KZru"
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist (df = edge_df, edge_attr = [\"osm_id\", \"name\", \"time\"], create_using  = nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vasyv-iJKgh2"
   },
   "source": [
    "With that preceding line of code, we have built a graph from a road network GeoDataframe. In the next section, we will be doing all of the exciting stuff such as performing analyses with this graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qpf35ERQKqJB"
   },
   "source": [
    "***Shortest path analyses on the road network graph***\n",
    "\n",
    "In this section, we will be performing some of the analyses that we did earlier on the new graph, such as the following:\n",
    "\n",
    "- Dijkstra's shortest path analysis\n",
    "- Dijkstra's shortest path cost\n",
    "- Single-source Dijkstra's path length\n",
    "\n",
    "***Dijkstra's shortest path analysis***\n",
    "\n",
    "We have waited so long to perform the shortest path analysis on our graph. So, without further ado, let's run the shortest path algorithm on our graph, optimizing for time. To run the shortest path algorithm, we need to know the source node ID and target node ID. Here, our node IDs are coordinates. Right now, let's pick the node IDs randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kg13Vf9GK7sh"
   },
   "outputs": [],
   "source": [
    "nodelist = list(G.nodes())\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceCBZV4rLGLL"
   },
   "source": [
    "The following lines of code select two nodes at random and assign them as the source and the target node, respectively. This is used as input to the dijkstra_path() function. As we have seen earlier, this function returns a list of node IDs in order, joining the ones that will make up the shortest path from the source node to the target node. Since the returned node IDs are already coordinates, we can create a Shapely LineString from it and plot it on the roads GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhfQ6nEYLWt7"
   },
   "outputs": [],
   "source": [
    "# Selecting random source and target\n",
    "src, target = nodelist[random.randint(0, len(nodelist)-1)], nodelist[random.randint(0, len(nodelist)-1)]\n",
    "\n",
    "#Calculating Shortest path\n",
    "sp = nx.dijkstra_path(G, src, target, weight='time')\n",
    "\n",
    "#Creating Shortest Path geometry with the result\n",
    "spd = gpd.GeoDataFrame({\"geometry\" : gpd.GeoSeries(LineString([(item) for item in sp]))})\n",
    "\n",
    "#Plot the geometry\n",
    "ax = roads_df.plot(color='gray', figsize = (12, 12), linewidth = 0.7, alpha = 0.5)\n",
    "spd.plot(ax=ax, color='black', linewidth=2)\n",
    "\n",
    "ax.text(src[0], src[1], s = 'Source', fontsize=12 ,color='r')\n",
    "ax.text(target[0], target[1], s = 'Target', fontsize=12, color='r')\n",
    "ax.scatter([src[0], target[0]],[src[1], target[1]], marker = '^', s = 100) #Markers\n",
    "\n",
    "ax.axis('equal')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLGuA11pM4FQ"
   },
   "source": [
    "This code generates a plot as follows. The dark line represents the shortest path between a source and target node in the road graph (represented by gray lines):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie1iPjR8M7pq"
   },
   "source": [
    "***Dijkstra's shortest path cost***\n",
    "\n",
    "To get the time cost of travel from the source node to the target node, just use the following one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypnTEYEQM_SM"
   },
   "outputs": [],
   "source": [
    "nx.dijkstra_path_length(G, src, target, weight='time')//60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygvBPSTBNChy"
   },
   "source": [
    "***Single source Dijkstra's shortest path cost***\n",
    "\n",
    "When we need to know the cost to reach all possible nodes from the source node, with a maximum accumulated cost of 30 minutes (1800 seconds), we can use the single_source_dijkstra_path_length() method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7fJZdBKNFZt"
   },
   "outputs": [],
   "source": [
    "spl = nx.single_source_dijkstra_path_length(G, src, cutoff = 1800, weight=\"time\")\n",
    "dict([spl.popitem() for i in range(0, 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMlLKUbjNNQc"
   },
   "source": [
    "The response of the method, stored in the splvariable, is a Python dictionary with the node IDs as the keys of the dictionary item and corresponding time cost (in seconds) to reach the node from the defined source node as dictionary values. The last ten items of the dictionary are displayed, as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sydxDbP8NTxh"
   },
   "source": [
    "***Concept of isochrones***\n",
    "\n",
    "Shortest paths are a navigational solution that provides the shortest paths and the shortest time (or distance) from a source to a target node. What if we need a solution with all possible areas that we can reach from a source node within a given time or distance cut-off? This is very important in commute-based searches, which can answer questions such as the following: \n",
    "\n",
    "- What are the nearest coffee shops within 15 minutes by car?\n",
    "- What are the open home listings that are 30 minutes from my office? \n",
    "- Can any fire truck stationed at its base location reach my house within 10 minutes? \n",
    "- What are the areas that are under-represented by public transit agencies?\n",
    "\n",
    "The idea we are looking at is known as an isochrone. Etymologically, it means same time (iso = same and chrono = time). More specifically, it means the areas that you can reach within the same time from a source location by a particular mode of transport under normal circumstances:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWjfiLFANh-u"
   },
   "source": [
    "The preceding graph shows the isochrone as a red, shaded area. The isochrone represents all possible locations that we can drive to from the yellow dot shown, as per our graph calculations. \n",
    "\n",
    "***Constructing an isochrone***\n",
    "\n",
    "As you might have guessed, we can use the response from the single_source_dijkstra_path_length() function to create an isochrone. But once we execute this method, we might have to further construct a polygon from the returned node locations. There are different methods to create a polygon given a mesh of points, but we will be discussing an approach known as the concave hull. Concave hulls are created by repeated triangulation of available points in the most efficient way. The implementation of this triangulation is provided by a scipy.spatial module known as Delaunay. The process of creating an isochrone polygon is as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLYX7k57NtuS"
   },
   "source": [
    "1. Create Delauney triangles with the location of the result nodes, as shown here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1NmQLNVNng_"
   },
   "outputs": [],
   "source": [
    "# Compute Delaunay triangles\n",
    "tri = Delaunay(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQxHDMsuNwQe"
   },
   "source": [
    "2. Loop through each triangle and calculate the circumradius of the triangle\n",
    "3. If the circumradius of the triangle is less than a preset value (say, 1/150), add the vertices of the triangle to a set\n",
    "4. Construct a series of polygons from the set of vertices\n",
    "5. Merge the polygons\n",
    "\n",
    "\n",
    "The code implementation of this logic can be found in the code repository under a function named generate_alpha_poly(). Once we have defined the alpha polygon generator function, we can use the response from our single_source_dijkstra_path_length() method, stored in the spl variable. Since we are using the cutoff parameter, we just need the keys of the spl dictionary. For a 30-minute isochrone, we will receive a lot of nodes as coordinates; hence, it is OK to round off the decimal degrees to 3 digits in the node coordinates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12DUk9qcODYk"
   },
   "outputs": [],
   "source": [
    "pts = np.array(list(spl.keys()))\n",
    "pts = np.round(pts, 3)\n",
    "pts = np.unique(pts,axis = 0)\n",
    "poly = generate_alpha_poly(pts, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z6iGNIROJ_G"
   },
   "source": [
    "When this polygon is plotted, it looks exactly like a plot that was shown at the beginning of this section: the diagram titled Isochrone. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZqp6zBur9grU+Bm7ofAVZ",
   "collapsed_sections": [],
   "name": "RoutingEngine(9b).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
